# -*- coding: utf-8 -*-
"""OCR_CPU.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n-KRya6g93r693Pw5GYJ0lGhcDsdm1tU
"""

# prompt:  create cpu based dnn ocr model that runs in real time processing using tesseracts lstm using images and videos as input and plain text as output

!pip install opencv-python
!pip install pytesseract
!sudo apt install tesseract-ocr
from google.colab.patches import cv2_imshow
import cv2
import pytesseract
import time

def process_image(image):
  # Preprocess the image (e.g., grayscale, thresholding)
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  # Use Tesseract LSTM OCR to extract text
  text = pytesseract.image_to_string(gray)
  return text

def process_video(video_path):
  cap = cv2.VideoCapture(video_path)
  while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
      break
    start_time = time.time()
    text = process_image(frame)
    end_time = time.time()
    fps = 1 / (end_time - start_time)
    print("Extracted Text:", text)
    print("FPS:", fps)
    cv2_imshow(frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
      break
  cap.release()
  cv2.destroyAllWindows()

# Example usage for image:
image_path = '/content/drive/MyDrive/docs.py/WhatsApp Image 2024-08-27 at 13.17.13_aae791b4.jpg'
image = cv2.imread(image_path)
text = process_image(image)
print("Extracted Text from Image:", text)

# Example usage for video:
video_path = '/content/drive/MyDrive/docs.py/Welcome to PowerPoint.mp4'
process_video(video_path)

from google.colab import drive
drive.mount('/content/drive')